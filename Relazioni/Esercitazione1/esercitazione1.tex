\raggedright
\mychapter{1}{Work Project 1}
	\label{ch:dt}
	Questo primo lavoro di gruppo si incentra sulla comprensione empirica dei \textsf{Decision Trees}, esempio di strumento ampiamente diffuso nel \textsf{ Machine Learning}, e sul \textsf{Problem Solving}, metodo scientifico applicato dall'\textsf{I.A.} per la risoluzione dei problemi.
	\section{Esercizio 1: Decision Trees}
		\label{sec:es1}
		\subsection{Esperimento: creazione Decision Tree}
		Un albero di decisione è un modello di rappresentazione delle decisioni e delle loro possibili conseguenze, costruito al fine di supportare l'azione decisionale. Costituisce un importante strumento nel contesto dell'\textsf{Inductive Learning}, in cui ricopre il ruolo di modello predittivo su cui si basa il comportamento dell'agente. La sua struttura discende da un insieme di esempi dati e determina le regole di condizione-azione atte alla classificazione di esempi futuri. Dunque l'agente è in grado di apprendere da una serie di dati il comportamento da assumere in situazioni non specificate.
		\subsubsection{Iris}
			Come primo esperimento abbiamo adoperato un insieme di dati facenti riferimento a varie specie di \emph{Iris}, le quali vengono caratterizzate da quattro attributi: lunghezza del sepalo, larghezza del sepalo, lunghezza del petalo, larghezza del petalo. Queste grandezze sono dimensionalmente espresse tutte in \emph{cm}. Il \emph{target} è, appunto, la tipologia di Iris.\par
			La dimensione complessiva del dataset è di 150 elementi. Per effettuare la prova è stato necessario formattare l'insieme dei dati originario, rendendolo consistente con le esigenze algoritmiche correlate al linguaggio utilizzato, \emph{Python} nel nostro caso.\par
			Gli esempi del dataset si presentano nella seguente forma:
			\lstinputlisting[lastline=1,backgroundcolor=\color{light-gray}]{iris.txt}
			Abbiamo, dunque, determinato i valori degli attributi per ciascun esempio in base alle virgole delimitatorie, riconosciuto i valori numerici precedentemente visti come stringhe (si è realizzato ciò mediante una funzione adibita allo scopo, sfruttante il casting) ed eliminato eventualmente il carattere di \textit{new line} al fine di evitare valori spuri.\par
			Di seguito la funzione implementata per caricare gli esempi dal file nella lista utilizzata nel programma:
			\medskip
			\begin{python}
		def aprifile(fil="nomefile.txt"):
			data=[]
			for line in file(fil):
				srt=line.split(',')
				for count in range(0,len(srt)):
					if(isfloat(srt[count])):
						srt[count]=float(srt[count])
					else :
						srt[count]=srt[count].strip('\n')
				data=data+[srt];
			return data
			\end{python}
			\bigskip
			Un campione di esempio formattato si presenterà, quindi, nella forma:
			\lstinputlisting[lastline=1,backgroundcolor=\color{light-gray}]{irisformattato.txt}
		
			Decidiamo di usare il 40\% dei dati forniti dal dataset come training set, quindi per effettuare l'apprendimento, ed il restante 60 \% per il test set. Per la determinazione di training set e test set si è utilizzata una funzione che seleziona un insieme casuale di esempi dal dataset di partenza, con cardinalità determinata dai parametri di ingresso in base alla percentuale desiderata (calcolo effettuato prima della chiamata).
			\bigskip
			\begin{python}
		def createdataset(data,numdati):
			tr=[]
			te=[]
			t=[]
			for i in range(0,numdati):
				t=random.choice(data);
				tr=tr+[t]
				num=data.index(t)
				del data[num]
			te=data
			return(tr,te)
			\end{python}
			\bigskip
			Costituito il training set, vengono sfruttati gli algoritmi forniti per la costruzione dell'albero (\texttt{buildtree}) e la relativa rappresentazione (\texttt{drawtree}).
		
			\includegraphics[scale=0.55]{iris.jpg}
		
			Otteniamo, infine, l'agognato albero di decisione!\par
			Come si evince dalla figura, il nodo scelto come radice è relativo alla terza colonna (colonna numero 2 da programma, poiché la numerazione rimarca quella delle liste in python) ed il valore che ne minimizza la funzione d'entropia è 3.6. Notiamo che questa scelta ci permette già la classificazione di 16 esempi.
			L'albero, attraverso le informazioni del training set, classifica tutti gli esempi, anche se, evidentemente, il \emph{guadagno informativo} degli attributi non sarà alto. Osserviamo, infatti, che un attributo non riesce a caratterizzare nettamente un gruppo di esempi. Conseguentemente, ciascuno di essi viene richiamato più volte per lo \emph{split} dei dati, aumentando inevitabilmente la profondità dell' albero.\par
			Alla luce di queste osservazioni possiamo giungere alla seguente considerazione: molto probabilmente questa classificazione non sarà abbastanza generalizzante ed, ipotizzando di utilizzare un test set sufficientemente vario, non ci offrirà ottimi risultati in termini di \emph{performance}. Si potrebbe, però, ricercare una maggiore generalizzazione tramite l'applicazione di tecniche di \emph{pruning}, che diminuirebbero la profondità dell'albero.\par
		\subsubsection{Mushrooms} 
			Analizziamo ora il dataset \emph{Mushroom}, relativo ai funghi. Il fine sarà quello di determinarne se un fungo sia commestibile o avvelenato. Il dataset è caratterizzato da ben 21 attributi e 8124 istanze. Utilizziamo sempre le medesime percentuali di dati per il training set ed il test set (40\%-60\%).
			
			\begin{sidewaysfigure}
				\includegraphics[width=1.2\textwidth, height=0.9\textheight]{mushroom.jpg}
				\caption{Mushrooms Decision Tree}
				\label{fig:mus-dt}
			\end{sidewaysfigure}
			
					
			L' albero, come si può osservare dalla figura \vref{fig:mus-dt}, classifica tutti gli esempi distintamente senza utilizzare tutti gli attributi forniti dal dataset. Esso si presenta, quindi, in una forma compatta e generalizzante.\par
			Ipotizziamo, allora, che l'albero sia stato costruito facendo uso di attributi rappresentativi con alto guadagno informativo, in grado di effettuare un chiaro split degli esempi sulla base dei valori da essi assunti.	
		\subsection{Esperimento: Learning Curve}
			Per valutare l'approssimazione dell'ipotesi alla funzione ideale (\textsf{Problem of Induction}) si utilizzano delle misure di \emph{performance}, senza le quali il solo albero delle decisioni risulta un modello incompleto. La misura di performance da noi adoperata fa uso di un test set per stimare l'accuratezza del modello di apprendimento. Essa può essere descritta mediante la \textsf{Learning Curve}, che rappresenta la percentuale di correttezza sul test set rispetto alle dimensioni del training set.\par
			In questo esperimento ci porremo, quindi, come obiettivo la ricerca di una curva di apprendimento. Si è scelto, al fine di preservare un test set consistente, di attribuire al training set dal 10\% fino al 50\% dell'intero data set.
			Il data set impiegato è inerente ad un censimento atto ad identificare gli individui con reddito superiore ai cinquanta mila dollari annui.\par
			La curva è stata prodotta facendo uso della funzione \texttt{fperformance}, che si avvale, a sua volta, di una funzione \texttt{performance} per il calcolo dell'\emph{accuracy}, e della libreria \textbf{matplotlib} per il tracciamento del grafico in questione. Al seguito di una fase iniziale, prevedente l'inizializzazione delle variabili (test set massimo) e la determinazione del numero di esempi corrispondete al 10\% del dataset, si procede con un ciclo di 5 iterazioni che implementa l'intera logica. Ad ogni ciclo, \texttt{createdataset} drena il 10\% del test set nel training set (memorizzato iterativamente nella lista \texttt{t}). Segue la creazione dell'albero, il calcolo della sua accuratezza, di cui la lista \texttt{p} memorizza i differenti valori da porre sull'asse delle ordinate, e l'aggiornamento della lista \texttt{perc}, che memorizza i valori dell'asse delle ascisse. Al termine del ciclo ci si avvale delle funzioni offerte dalla libreria per la rappresentazione grafica della curva.
			\bigskip
			\begin{python}
		def fperformance(data):
			testc=data
			percent=10
			p=[]
			perc=[]
			t=[]
			numdati=(int)((float)(len(testc))/100*percent);
			for i in range(0,5):
				(train,testc)=createdataset(testc,numdati)
				t=t+train;
				tree=buildtree(t)
				p=p+[performance(tree,testc)]
				perc=perc+[percent]
				percent=percent+10;
			line,=plt.plot(perc,p,'r-')
			plt.xlabel('percentuale dati training')
			plt.ylabel('percentuale successi')
			line.set_antialiased(False)
			plt.show()
			
			
		def performance(tree,test):
			t=0
			for row in test:
				results=classify(row,tree)
				for r in results:
					if r==row[len(row)-1]:
						t=t+1
			percent=float(t)/len(test)
			return percent
			\end{python}
			\bigskip
		
			Abbiamo fatto uso della funzione \texttt{performance} per il calcolo dell'accuratezza. Essa effettua, tramite l'albero, la classificazione per ogni esempio del test set (esito in una variabile dizionario \texttt{results}) ed effettua un conteggio nel caso in cui il risultato ottenuto sia coerente con il relativo \emph{target}. Si ottiene, infine, la percentuale di correttezza sul test set tramite il rapporto tra gli esempi correttamente classificati e quelli totali.\par
			Visualizziamo graficamente il prodotto di questo algoritmo sul dataset di riferimento.
			
			\includegraphics[scale=0.86]{performance.png}
			 
			Come si evince dal grafico, la nostra accuratezza migliora fino al 40\%, dopodiché si percepisce un degrado dell'apprendimento all'aumentare dei dati forniti al training set. Abbiamo interpretato questo andamento supponendo che, con l'incremento di quest'ultimo, si venga a costituire un albero più specifico (\emph{overfitting}), ovvero con meno capacità di classificare gli esempi.\par
			Osservando la curva di apprendimento, si è ipotizzato che questa rappresentazione dell'ambiente descritto dal dataset presenti un'espressività ridondante. Ciò è stato dedotto dall'analisi della crescita, lenta nell'intervallo di riferimento: al crescere del training set dal 10\% al 50\% si rileva un aumento massimo di circa 1\%. Per migliorare la rapidità della curva si potrebbe considerare un insieme ridotto di attributi, ricercando una rappresentazione, mediante albero di decisione, più compatta. Nella determinazione degli attributi si  dovrebbe tentare di evitare la ridondanza, eventualmente focalizzandosi su quelli più rappresentativi e con un alto guadagno informativo.
		\subsection{Domanda 1}
			Un agente in grado di apprendere mediante alberi di decisione fonda questo suo processo su principi di apprendimento induttivo (\textsf{inductive learning}). L'apprendimento induttivo è una forma di apprendimento basata sull'induzione a partire da esempi dati. Esso, data una collezione di esempi (\textsf{training set}) della funzione \textsf{target} \emph{f} che si vorrebbe imparare, mira a restituire una funzione \emph{h} (\textsf{hypothesis}) che approssimi al meglio la \emph{f}. Concettualmente, il criterio nella determinazione di \emph{h} tra le differenti funzioni dello spazio delle ipotesi dovrebbe essere legato, più che alla consistenza nello spiegare i dati, alla bontà dell'approssimazione e quindi alla capacità di generalizzazione per predire esempi non ancora incontrati. In questo senso, l'agente agisce in modo razionale poichè cerca di \textbf{decidere come comportarsi in situazioni a lui sconosciute basandosi su quelle già note}. Possiamo individuare proprio in questo aspetto una \textbf{forma di intelligenza}, determinata dall'agire razionalmente.
		\bigskip
		\subsection{Domanda 2}
			Le procedure di \textsf{Decision Tree Learning} consentono la costruzione di un albero di decisione "piccolo", consistente con gli esempi forniti in input per la determinazione di tale struttura. Ogni nodo interno all'albero corrisponde ad una condizione sul valore di un attributo, gli archi verso i nodi figli ai possibili valori per quell'attributo, le foglie alla classificazione. Si ottiene così, attraverso i \textsf{path} dell'albero, una rappresentazione compatta delle regole di condizione-azione. L'albero di decisione prende in input una situazione descritta da un insieme di attributi e restituisce una decisione, ovvero il valore predetto di uscita per tale input, sulla base del cammino percorso. In questo senso possiamo parlare di apprendimento, poiché, \textbf{alla luce di un dato insieme di esempi, si viene a costituire un albero di decisione dalla ben determinata topologia e legge condizione-azione, utilizzabile per la classificazione di esempi futuri}.
	\section{Esercizio 2: Problem Solving}
		\label{sec:es2}
		Il problema descritto è del tipo \emph{non deterministico} e \emph{parzialmente osservabile}, quindi classificabile come \textsf{Contingency Problem}. Essendo il pianeta caratterizzato da una proprietà di elasticità geografica, possiamo immaginare che forze esterne, ad ogni cambio di città del robot, facciano variare le distanze tra le differenti città, incrementandole o diminuendole. Per tale motivo l'algoritmo di navigazione proposto fa uso di un albero di ricerca con strategia di analisi in profondità (\textsf{depth-first search}), la quale prevede di espandere primariamente il nodo più profondo non espanso.\par
		L'alterazione non deterministica delle distanze ci ha spinto a sottolineare l'importanza di \textbf{minimizzare il numero di città percorse} lungo il tragitto verso l'obiettivo. Un maggior numero di città attraversate aumenterebbe probabilisticamente la distanza percorsa. Sarebbe, quindi, auspicabile evitare, o minimizzare, il numero di processi di risalita dell'albero, che prevederebbero il ritorno alle stesse città più volte, e continuare nella navigazione in profondità, sfruttando, nel migliore dei casi, la possibilità di arrivare al \textsf{goal} senza attuare un \textsf{backtracking}.\par
		Un'ulteriore scelta, dettata dalla natura del problema, riguarda l'utilizzo della struttura dati lista semplice. Ciò dipende dal fatto che, in questo esempio, le distanze tra le città non sono costanti ed anzi considerate varianti in maniera non predicibile e non deterministica. Quindi, la struttura dati lista, ordinata in base alla distanza, non si adatta a tale tipologia di problema (a differenza di quello trattato in classe).\par
		Inoltre, per evitare l'insorgere di cicli, si è previsto di tenere traccia dell'insieme dei nodi già esplorati mediante l'utilizzo di una lista \textsf{closed}, ottenendo in definitiva un algoritmo del tipo \textsf{Graph Search}.
